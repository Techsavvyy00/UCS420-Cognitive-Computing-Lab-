{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYiqhVnyWJ4D6aAruNG9oZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
   
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQkeLGGWPzkb",
        "outputId": "081ec923-1fc1-40e8-d463-53c7dbbef72f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.  Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports, technology, food, books, etc.).\n",
        "1.\tConvert text to lowercase and remove punctuation using re.\n",
        "2.\tTokenize the text into words and sentences.\n",
        "3.\tSplit using split() and word_tokenize() and compare how Python split and NLTK’s word_tokenize() differ.\n",
        "4.\tRemove stopwords (using NLTK's stopwords list).\n",
        "5.\tDisplay word frequency distribution (excluding stopwords).\n"
      ],
      "metadata": {
        "id": "UY_Nr2H_N_Ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph=\"In water, I feel light, like I’m floating through the sky.The world goes silent, and all my worries pass by. It keeps me strong, calm, and clears my mind, that’s why I love swimming — it’s my peace I find\"\n",
        "\n",
        "text = re.sub(r'[^\\w\\s]', '', paragraph.lower())\n",
        "\n",
        "words = word_tokenize(text)\n",
        "sentences = sent_tokenize(paragraph)\n",
        "\n",
        "\n",
        "split_words = text.split()\n",
        "print(\"Split words:\", split_words[:20])\n",
        "print(\"Word_tokenize:\", words[:20])\n",
        "print(\"Difference:\", set(split_words) - set(words))\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "\n",
        "word_freq = FreqDist(filtered_words)\n",
        "print(\"\\nWord Frequency Distribution (excluding stopwords):\")\n",
        "word_freq.most_common()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuTSz4uCOQuB",
        "outputId": "4cf2b548-fcb4-4503-d228-8c3b152edb31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split words: ['in', 'water', 'i', 'feel', 'light', 'like', 'im', 'floating', 'through', 'the', 'skythe', 'world', 'goes', 'silent', 'and', 'all', 'my', 'worries', 'pass', 'by']\n",
            "Word_tokenize: ['in', 'water', 'i', 'feel', 'light', 'like', 'im', 'floating', 'through', 'the', 'skythe', 'world', 'goes', 'silent', 'and', 'all', 'my', 'worries', 'pass', 'by']\n",
            "Difference: set()\n",
            "\n",
            "Word Frequency Distribution (excluding stopwords):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('water', 1),\n",
              " ('feel', 1),\n",
              " ('light', 1),\n",
              " ('like', 1),\n",
              " ('im', 1),\n",
              " ('floating', 1),\n",
              " ('skythe', 1),\n",
              " ('world', 1),\n",
              " ('goes', 1),\n",
              " ('silent', 1),\n",
              " ('worries', 1),\n",
              " ('pass', 1),\n",
              " ('keeps', 1),\n",
              " ('strong', 1),\n",
              " ('calm', 1),\n",
              " ('clears', 1),\n",
              " ('mind', 1),\n",
              " ('thats', 1),\n",
              " ('love', 1),\n",
              " ('swimming', 1),\n",
              " ('peace', 1),\n",
              " ('find', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Using the same paragraph from Q1:\n",
        "1.\tExtract all words with only alphabets using re.findall()\n",
        "2.\tRemove stop words using NLTK’s stopword list\n",
        "3.\tPerform stemming with PorterStemmer\n",
        "4.\tPerform lemmatization with WordNetLemmatizer\n",
        "5.\tCompare the stemmed and lemmatized outputs and explain when you’d prefer one over the other.\n"
      ],
      "metadata": {
        "id": "MZoe4-8pQFx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#1\n",
        "words = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
        "print(words)\n",
        "#2\n",
        "filtered_words = [w for w in words if w not in stop_words] # Changed 'word' to 'w'\n",
        "print(filtered_words)\n",
        "ps = PorterStemmer()\n",
        "lm = WordNetLemmatizer()\n",
        "data = []\n",
        "for word in filtered_words:\n",
        "  porter_stem = ps.stem(word)\n",
        "  lemma = lm.lemmatize(word)\n",
        "  data.append([word, porter_stem, lemma])\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"Word\", \"PorterStemmed Word\", \"Lemmatizer Word\"])\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "tsog86bbQNPU",
        "outputId": "d02afab6-675c-4dc6-85c2-ae6dd88107c5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in', 'water', 'i', 'feel', 'light', 'like', 'im', 'floating', 'through', 'the', 'skythe', 'world', 'goes', 'silent', 'and', 'all', 'my', 'worries', 'pass', 'by', 'it', 'keeps', 'me', 'strong', 'calm', 'and', 'clears', 'my', 'mind', 'thats', 'why', 'i', 'love', 'swimming', 'its', 'my', 'peace', 'i', 'find']\n",
            "['water', 'feel', 'light', 'like', 'im', 'floating', 'skythe', 'world', 'goes', 'silent', 'worries', 'pass', 'keeps', 'strong', 'calm', 'clears', 'mind', 'thats', 'love', 'swimming', 'peace', 'find']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Word PorterStemmed Word Lemmatizer Word\n",
              "0      water              water           water\n",
              "1       feel               feel            feel\n",
              "2      light              light           light\n",
              "3       like               like            like\n",
              "4         im                 im              im\n",
              "5   floating              float        floating\n",
              "6     skythe              skyth          skythe\n",
              "7      world              world           world\n",
              "8       goes                goe              go\n",
              "9     silent             silent          silent\n",
              "10   worries              worri           worry\n",
              "11      pass               pass             pas\n",
              "12     keeps               keep            keep\n",
              "13    strong             strong          strong\n",
              "14      calm               calm            calm\n",
              "15    clears              clear           clear\n",
              "16      mind               mind            mind\n",
              "17     thats               that           thats\n",
              "18      love               love            love\n",
              "19  swimming               swim        swimming\n",
              "20     peace               peac           peace\n",
              "21      find               find            find"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-459c0102-95f6-4b16-a6f3-162191324f30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>PorterStemmed Word</th>\n",
              "      <th>Lemmatizer Word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>water</td>\n",
              "      <td>water</td>\n",
              "      <td>water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>feel</td>\n",
              "      <td>feel</td>\n",
              "      <td>feel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>light</td>\n",
              "      <td>light</td>\n",
              "      <td>light</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>like</td>\n",
              "      <td>like</td>\n",
              "      <td>like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>im</td>\n",
              "      <td>im</td>\n",
              "      <td>im</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>floating</td>\n",
              "      <td>float</td>\n",
              "      <td>floating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>skythe</td>\n",
              "      <td>skyth</td>\n",
              "      <td>skythe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>world</td>\n",
              "      <td>world</td>\n",
              "      <td>world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>goes</td>\n",
              "      <td>goe</td>\n",
              "      <td>go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>silent</td>\n",
              "      <td>silent</td>\n",
              "      <td>silent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>worries</td>\n",
              "      <td>worri</td>\n",
              "      <td>worry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>pass</td>\n",
              "      <td>pass</td>\n",
              "      <td>pas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>keeps</td>\n",
              "      <td>keep</td>\n",
              "      <td>keep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>strong</td>\n",
              "      <td>strong</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>calm</td>\n",
              "      <td>calm</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>clears</td>\n",
              "      <td>clear</td>\n",
              "      <td>clear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>mind</td>\n",
              "      <td>mind</td>\n",
              "      <td>mind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>thats</td>\n",
              "      <td>that</td>\n",
              "      <td>thats</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>love</td>\n",
              "      <td>love</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>swimming</td>\n",
              "      <td>swim</td>\n",
              "      <td>swimming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>peace</td>\n",
              "      <td>peac</td>\n",
              "      <td>peace</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>find</td>\n",
              "      <td>find</td>\n",
              "      <td>find</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-459c0102-95f6-4b16-a6f3-162191324f30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-459c0102-95f6-4b16-a6f3-162191324f30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-459c0102-95f6-4b16-a6f3-162191324f30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ed052b4-c658-4c6f-8e09-ded516f2fef3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ed052b4-c658-4c6f-8e09-ded516f2fef3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ed052b4-c658-4c6f-8e09-ded516f2fef3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1a3f71ad-9bf2-4291-ae6d-af7c8e55dd55\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1a3f71ad-9bf2-4291-ae6d-af7c8e55dd55 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"water\",\n          \"strong\",\n          \"goes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PorterStemmed Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"water\",\n          \"strong\",\n          \"goe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmatizer Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"water\",\n          \"strong\",\n          \"go\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Choose 3 short texts of your own (e.g., different news headlines, product reviews).\n",
        "1.\tUse CountVectorizer to generate the Bag of Words representation.\n",
        "2.\tUse TfidfVectorizer to compute TF-IDF scores.\n",
        "3.\tPrint and interpret the top 3 keywords from each text using TF-IDF.\n"
      ],
      "metadata": {
        "id": "UApR7S8DQTeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#1\n",
        "texts = [\"Surge in Violent Crime Across Major Cities Raises Alarm, Authorities Urge Immediate Action to Combat Rising Threats to Public Safety\"]\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(texts)\n",
        "print(cv.get_feature_names_out())\n",
        "print(\"---------------------------------------------\")\n",
        "print(X.toarray())\n",
        "#2\n",
        "print(\"---------------------------------------------\")\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(texts)\n",
        "feature_names = tfidf.get_feature_names_out()\n",
        "print(feature_names)\n",
        "print(\"---------------------------------------------\")\n",
        "print(tfidf_matrix.toarray())\n",
        "print(\"---------------------------------------------\")\n",
        "#3\n",
        "for i, text in enumerate(texts):\n",
        "    tfidf_scores = tfidf_matrix[i].toarray()[0]\n",
        "    sorted_indices = tfidf_scores.argsort()[::-1]  # Sort indices in descending order\n",
        "    top_keywords = [feature_names[j] for j in sorted_indices[:3]]\n",
        "    print(f\"Text {i + 1}: {text}\")\n",
        "    print(\"---------------------------------------------\")\n",
        "    print(f\"Top 3 keywords: {top_keywords}\\n\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQE2WCviQapG",
        "outputId": "f1df2a46-9ff4-4a5c-cff9-ab0ce0b7e7a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['across' 'action' 'alarm' 'authorities' 'cities' 'combat' 'crime'\n",
            " 'immediate' 'in' 'major' 'public' 'raises' 'rising' 'safety' 'surge'\n",
            " 'threats' 'to' 'urge' 'violent']\n",
            "---------------------------------------------\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1]]\n",
            "---------------------------------------------\n",
            "['across' 'action' 'alarm' 'authorities' 'cities' 'combat' 'crime'\n",
            " 'immediate' 'in' 'major' 'public' 'raises' 'rising' 'safety' 'surge'\n",
            " 'threats' 'to' 'urge' 'violent']\n",
            "---------------------------------------------\n",
            "[[0.21320072 0.21320072 0.21320072 0.21320072 0.21320072 0.21320072\n",
            "  0.21320072 0.21320072 0.21320072 0.21320072 0.21320072 0.21320072\n",
            "  0.21320072 0.21320072 0.21320072 0.21320072 0.42640143 0.21320072\n",
            "  0.21320072]]\n",
            "---------------------------------------------\n",
            "Text 1: Surge in Violent Crime Across Major Cities Raises Alarm, Authorities Urge Immediate Action to Combat Rising Threats to Public Safety\n",
            "---------------------------------------------\n",
            "Top 3 keywords: ['to', 'violent', 'urge']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Write 2 short texts (4–6 lines each) describing two different technologies (e.g., AI vs Blockchain).\n",
        "1.\tPreprocess and tokenize both texts.\n",
        "2.\tCalculate:\n",
        "a.\tJaccard Similarity using sets\n",
        "b.\tCosine Similarity using TfidfVectorizer + cosine_similarity()\n",
        "c.\tAnalyze which similarity metric gives better insights in your case.\n"
      ],
      "metadata": {
        "id": "qraAakfYQfkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "A = \"\"\"\n",
        "Artificial Intelligence enables machines to learn and make decisions.\n",
        "It's used in chatbots, self-driving cars, and medical diagnostics.\n",
        "AI improves efficiency by automating complex tasks.\"\"\"\n",
        "B = \"\"\"\n",
        "Blockchain is a secure, decentralized digital ledger system.\n",
        "It records transactions transparently across multiple computers.\n",
        "Common uses include cryptocurrencies and smart contracts.\n",
        "\"\"\"\n",
        "# 1. Preprocess and Tokenize\n",
        "texts1 = re.sub(r'[^\\w\\s]', '', A.lower())\n",
        "print(texts1)\n",
        "print(\"------------------------------------------------\")\n",
        "texts2 = re.sub(r'[^\\w\\s]', '', B.lower())\n",
        "print(texts2)\n",
        "print(\"------------------------------------------------\")\n",
        "text1 = set(texts1.split())\n",
        "print(text1)\n",
        "print(\"------------------------------------------------\")\n",
        "text2 = set(texts2.split())\n",
        "print(text2)\n",
        "print(\"------------------------------------------------\")\n",
        "# 3. Intersection\n",
        "jaccard = len(text1.intersection(text2)) / len(text1.union(text2))\n",
        "print(\"Jaccard Similarity:\", jaccard)\n",
        "print(\"------------------------------------------------\")\n",
        "# Ensure TfidfVectorizer is imported\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer # Already imported at the beginning\n",
        "\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "vecs = tfidf_vec.fit_transform([texts1, texts2])\n",
        "cos_sim = cosine_similarity(vecs[0:1], vecs[1:2])\n",
        "print(\"Cosine Similarity:\", cos_sim[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bHQpOFRQi8b",
        "outputId": "e2844e3d-be7c-4798-e7da-ff8e95092cbe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "artificial intelligence enables machines to learn and make decisions\n",
            "its used in chatbots selfdriving cars and medical diagnostics\n",
            "ai improves efficiency by automating complex tasks\n",
            "------------------------------------------------\n",
            "\n",
            "blockchain is a secure decentralized digital ledger system\n",
            "it records transactions transparently across multiple computers\n",
            "common uses include cryptocurrencies and smart contracts\n",
            "\n",
            "------------------------------------------------\n",
            "{'make', 'intelligence', 'efficiency', 'tasks', 'by', 'used', 'improves', 'selfdriving', 'to', 'enables', 'diagnostics', 'automating', 'medical', 'in', 'its', 'learn', 'ai', 'and', 'decisions', 'chatbots', 'artificial', 'cars', 'machines', 'complex'}\n",
            "------------------------------------------------\n",
            "{'blockchain', 'common', 'decentralized', 'is', 'transparently', 'contracts', 'ledger', 'digital', 'records', 'across', 'and', 'multiple', 'it', 'computers', 'system', 'cryptocurrencies', 'uses', 'secure', 'smart', 'a', 'include', 'transactions'}\n",
            "------------------------------------------------\n",
            "Jaccard Similarity: 0.022222222222222223\n",
            "------------------------------------------------\n",
            "Cosine Similarity: 0.04469510534039099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q5. Write a short review for a product or service.\n",
        "1.\tUse TextBlob or VADER to find polarity & subjectivity for each review.\n",
        "2.\tClassify reviews into Positive / Negative / Neutral.\n",
        "3.\tCreate a word cloud using the wordcloud library for all positive reviews.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RNZPxVbKQj_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "#1\n",
        "reviews = ['''The Fenty Beauty Gloss Bomb is a must-have for anyone looking for a high-shine, non-sticky gloss.\n",
        " Its formula is smooth, hydrating, and gives lips a plumped-up look without feeling heavy.\n",
        " The universally flattering shade, Fenty Glow, adds a subtle shimmer, making it perfect for both everyday wear and special occasions.\n",
        " I love how it moisturizes while providing a beautiful gloss finish that lasts for hours.\n",
        "  Overall, it’s a top-tier product that delivers both quality and style!''']\n",
        "positive_reviews = []\n",
        "for(i,review) in enumerate(reviews):\n",
        "  blob = TextBlob(review)\n",
        "  polarity = blob.sentiment.polarity\n",
        "  subjectivity = blob.sentiment.subjectivity\n",
        "  print(f\"Review: {review}\")\n",
        "  print(f\"Polarity: {polarity}\")\n",
        "  print(f\"Subjectivity: {subjectivity}\")\n",
        "  if polarity > 0.1:\n",
        "      sentiment = \"Positive\"\n",
        "      positive_reviews.append(review)\n",
        "  elif polarity < -0.1:\n",
        "      sentiment = \"Negative\"\n",
        "  else:\n",
        "      sentiment = \"Neutral\"\n",
        "  print(f\"Sentiment: {sentiment}\")\n",
        "  print(\"------------------------------------------------\")\n",
        "\n",
        "#3\n",
        "all_positive_text = \" \".join(positive_reviews)\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='black').generate(all_positive_text)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "4unsk2LeQkhi",
        "outputId": "27558b3a-f817-4db0-93fc-21ab651a27ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: The Fenty Beauty Gloss Bomb is a must-have for anyone looking for a high-shine, non-sticky gloss.\n",
            " Its formula is smooth, hydrating, and gives lips a plumped-up look without feeling heavy. \n",
            " The universally flattering shade, Fenty Glow, adds a subtle shimmer, making it perfect for both everyday wear and special occasions. \n",
            " I love how it moisturizes while providing a beautiful gloss finish that lasts for hours.\n",
            "  Overall, it’s a top-tier product that delivers both quality and style!\n",
            "Polarity: 0.2373809523809524\n",
            "Subjectivity: 0.5271428571428571\n",
            "Sentiment: Positive\n",
            "------------------------------------------------\n"
          ]
        },
        
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Choose your own paragraph (~100 words) as training data.\n",
        "1.\tTokenize text using Tokenizer() from keras.preprocessing.text\n",
        "2.\tCreate input sequences and build a simple LSTM or Dense model\n",
        "3.\tTrain the model and generate 2–3 new lines of text starting from any seed word you provide.\n"
      ],
      "metadata": {
        "id": "_GBToZh_Qrvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import random\n",
        "# Import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Paragraph\n",
        "text = \"\"\"Artificial intelligence has rapidly transformed industries across the globe,\n",
        "revolutionizing how we approach problem-solving and decision-making.\n",
        "From healthcare to finance, AI systems are being used to analyze vast amounts of data, uncover patterns,\n",
        "and generate insights with unprecedented accuracy. Machine learning models, particularly deep learning architectures,\n",
        "have demonstrated remarkable capabilities in image recognition, natural language processing, and predictive analytics.\n",
        "However, as AI becomes more embedded in daily life, ethical concerns around bias, privacy,and accountability have also come to the forefront,\n",
        "emphasizing the need for responsible development and deployment of these powerful technologies\"\"\"\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences\n",
        "input_sequences = []\n",
        "for line in text.split(\".\"):\n",
        "    tokens = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(tokens)):\n",
        "        n_gram_sequence = tokens[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Create features and labels\n",
        "X = input_sequences[:,:-1]\n",
        "y = input_sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=total_words) # Now to_categorical is defined\n",
        "print(\"--------------------------------------------------------------------\")\n",
        "\n",
        "model = Sequential()\n",
        "# Change input_dim to total_words or a higher value\n",
        "model.add(Embedding(input_dim=total_words, output_dim=10, input_length= input_sequences.shape[1]))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(len(tokenizer.word_index)+1, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "def generate_lines(seed_text, total_lines=3, words_per_line=7):\n",
        "    generated_text = \"\"\n",
        "    current_seed = seed_text\n",
        "\n",
        "    for _ in range(total_lines):\n",
        "        line = \"\"\n",
        "        for _ in range(words_per_line):\n",
        "            token_list = tokenizer.texts_to_sequences([current_seed])[0]\n",
        "            token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "            predicted = model.predict(token_list, verbose=0)\n",
        "            predicted_word_index = np.argmax(predicted, axis=1)[0]\n",
        "\n",
        "            output_word = \"\"\n",
        "            for word, index in tokenizer.word_index.items():\n",
        "                if index == predicted_word_index:\n",
        "                    output_word = word\n",
        "                    break\n",
        "\n",
        "            # Handle out-of-vocabulary words\n",
        "            if output_word == \"\":\n",
        "                output_word = \"[OOV]\"  # Replace with a placeholder or handle differently\n",
        "\n",
        "            current_seed += \" \" + output_word\n",
        "            line += output_word + \" \"\n",
        "        generated_text += line.strip() + \"\\n\"\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Try generating 3 lines of text from a seed word\n",
        "seed = \"Technology\"\n",
        "print(generate_lines(seed))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "_eT7tzPmQsQt",
        "outputId": "c973bb71-edd2-4c49-8f0a-d6d0b840c22d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------\n"
          ]
        },
        
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "to to to to to deployment deployment\n",
            "powerful powerful across powerful across analyze across\n",
            "powerful across powerful across analyze technologies across\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
